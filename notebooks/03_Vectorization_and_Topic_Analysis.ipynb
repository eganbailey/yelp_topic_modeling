{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorization and Topic Analysis\n",
    "\n",
    "In this notebook, we use sklearn's tf-idf vectorizer on our restaurant and business review corpus and perform topic analysis on the reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import spacy\n",
    "import textacy\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation, NMF, TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/tokenized.pkl', 'rb') as f:\n",
    "    rests = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the custom vectorizer\n",
    "\n",
    "Since I previously used spacy to tokenize the restaurant reviews, I can't use the default tf-idf vectorizer from sklearn since by default the vectorizer incorporates an analyzer, tokenizer, and preprocessor; we've already done the tokenizer and preprocessing in Notebook 2. I will need to construct a custom vectorizer using the tf-idf framework to vectorize our text for topic analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity(doc):\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(analyzer='word', \n",
    "                             tokenizer=identity, \n",
    "                             preprocessor=identity, \n",
    "                             token_pattern=None, \n",
    "                             min_df=5, \n",
    "                             max_df=0.95, \n",
    "                             max_features=100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create document-term matrices for the two review corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 37s, sys: 3.08 s, total: 1min 40s\n",
      "Wall time: 1min 40s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "doc_term_matrix = vectorizer.fit_transform((doc for doc in rests))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create topic models and print out topics\n",
    "\n",
    "Let's compare the topic generation of two decomposition models: Latent Semantic Analysis (LSA), and non-Negative Matrix Factorization (NMF)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topic_model(input_matrix, model_name, n_topics):\n",
    "    model = textacy.TopicModel(model_name, n_topics=n_topics)\n",
    "    model.fit(input_matrix)\n",
    "    doc_topic_matrix = model.transform(input_matrix)\n",
    "\n",
    "    for topic_idx, top_terms in model.top_topic_terms(vectorizer.get_feature_names()):\n",
    "        print('topic', topic_idx, ':', '   '.join(top_terms))\n",
    "        \n",
    "    for topic_idx, top_docs in model.top_topic_docs(doc_topic_matrix, topics=[0,1], top_n=2):\n",
    "        print(topic_idx)\n",
    "        for j in top_docs:\n",
    "            print(rests[j])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic 0 : numb   be   that   this   they   with   place   have   great   order\n",
      "topic 1 : great   place   service   friendly   very   amaze   always   staff   this   delicious\n",
      "topic 2 : pizza   crust   numb   slice   wing   delivery   topping   cheese   pepperoni   order\n",
      "topic 3 : numb   great   service   minute   price   atmosphere   friendly   sushi   staff   star\n",
      "topic 4 : place   this   have   they   always   sushi   that   there   never   when\n",
      "topic 5 : place   this   numb   chicken   sushi   fry   sandwich   fresh   price   sauce\n",
      "topic 6 : very   sushi   this   restaurant   place   back   be   will   definitely   pizza\n",
      "topic 7 : sushi   they   very   always   their   have   fresh   price   roll   friendly\n",
      "topic 8 : sushi   great   that   with   much   price   roll   buffet   really   some\n",
      "topic 9 : sushi   order   chicken   fry   service   burger   here   back   will   always\n",
      "topic 10 : burger   very   fry   sushi   burgers   friendly   staff   they   price   be\n",
      "topic 11 : very   chicken   order   great   they   place   price   customer   wing   that\n",
      "topic 12 : be   chicken   have   always   restaurant   time   here   fry   this   wing\n",
      "topic 13 : price   here   back   will   much   chicken   buffet   definitely   well   again\n",
      "topic 14 : always   that   restaurant   service   here   burger   friendly   there   location   much\n",
      "topic 15 : service   restaurant   amaze   their   recommend   excellent   that   they   delicious   highly\n",
      "topic 16 : really   staff   friendly   tacos   drink   back   definitely   chicken   awesome   super\n",
      "topic 17 : sandwich   that   chicken   staff   have   amaze   friendly   restaurant   sushi   ever\n",
      "topic 18 : breakfast   their   amaze   friendly   be   service   staff   chicken   there   coffee\n",
      "topic 19 : amaze   here   very   order   breakfast   that   really   just   great   everything\n",
      "0\n",
      "['where', 'start', '\\ufeff1', 'down', 'street', 'from', 'enjoy', 'frequent', 'this', 'place', 'because', 'convenient', 'location', 'eat', 'here', 'many', 'many', 'time', 'would', 'that', 'little', 'once', 'month', 'next', 'this', 'there', 'quite', 'numb', 'other', 'sushi', 'place', 'along', 'queen', 'street', 'some', 'sketchy', 'avoid', 'them', 'much', 'presentable', 'look', 'they', 'have', 'which', 'prefer', 'which', 'another', 'reason', 'choose', 'always', 'great', 'quality', 'good', 'much', 'part', 'last', 'there', 'order', 'chicken', 'katsu', 'boyfriend', 'order', 'think', 'sweet', 'chicken', 'chicken', 'katsu', 'very', 'satisfy', 'there', 'much', 'batter', 'than', 'chicken', 'whole', 'thing', 'just', 'taste', 'fry', 'batter', 'look', 'be', 'change', 'while', 'maybe', 'look', 'sweet', 'chicken', 'be', 'fry', 'same', 'look', 'quite', 'greasy', 'speak', 'fry', 'that', 'however', 'that', 'their', 'tempura', 'great', 'because', 'always', 'shrimp', 'tempura', 'here', 'batter', 'always', 'crispy', 'look', 'tempura', 'fry', 'clean', 'much', 'often', 'than', 'this', 'place', 'pack', 'that', 'case', 'will', 'have', 'little', 'seat', 'about', 'numb', 'numb', 'typically', 'lineup', 'grow', 'quickly', 'tend', 'disorganize', 'they', 'usually', 'take', 'name', 'they', 'just', 'numb', 'people', 'service', 'every', 'here', 'experience', 'service', 'always', 'wonder', 'keep', 'come', 'back', 'choose', 'forget', 'about', 'terrible', 'service', 'because', 'always', 'satisfy', 'however', 'last', 'there', 'service', 'seem', 'exceptionally', 'terrible', 'server', 'always', 'miserable', 'often', 'seem', 'have', 'attitude', 'about', 'them', 'previously', 'mention', 'have', 'be', 'here', 'countless', 'numb', 'time', 'last', '\\ufeff1', 'friendly', 'seemingly', 'happy', 'server', 'this', 'restaurant', 'remember', 'make', 'comment', 'boyfriend', 'about', 'surprisingly', 'friendly', 'very', 'server', 'that', 'when', 'think', 'about', 'that', 'conversation', 'blow', 'friendly', 'service', 'should', 'standard', 'exception', 'think', 'recognize', 'wonder', 'seem', 'they', 'have', 'dedicate', 'server', 'table', 'section', 'when', 'particularly', 'which', 'often', 'have', 'about', 'numb', 'different', 'server', 'provide', 'with', 'assed', 'service', 'last', 'visit', 'place', '\\ufeff1', 'order', 'shortly', 'after', 'be', 'seat', 'only', 'moment', 'after', '2', 'waiter', 'attempt', 'take', 'order', '2', 'order', 'order', 'cheese', 'wontons', 'serve', 'numb', 'second', 'after', 'order', 'place', 'pretty', 'waiter', 'even', 'order', 'server', 'already', 'bring', 'wontons', 'numb', 'minute', 'late', 'another', 'serve', 'wontons', 'them', 'that', 'already', 'get', 'them', 'other', 'sometimes', 'they', 'will', 'forget', 'bring', 'part', 'your', 'order', 'good', 'perhaps', 'serve', 'another', 'table', 'accident', 'this', 'happen', 'visit', 'last', 'there', 'order', 'shrimp', 'tempura', 'with', '\\ufeff1', 'order', 'with', 'waiter', 'numb', 'never', 'someone', 'from', 'kitchen', 'serve', 'something', 'from', '2', 'order', 'ask', 'about', 'shrimp', 'tempura', 'would', 'check', 'retreat', 'back', 'into', 'kitchen', 'never', 'again', 'then', 'ask', 'waiter', 'numb', 'about', 'again', 'that', 'after', 'about', 'numb', 'much', 'minute', 'ask', 'waiter', 'numb', 'about', 'would', 'check', 'this', 'point', 'already', 'finish', 'everything', 'else', 'order', 'after', 'about', 'numb', 'much', 'minute', 'with', 'wait', 'that', 'just', 'ask', 'them', 'forget', 'about', 'shrimp', 'tempura', 'waiter', 'numb', 'come', 'right', 'just', 'order', 'just', 'order', 'which', 'that', 'order', 'when', '\\ufeff1', 'down', 'about', 'early', 'also', 'that', 'table', 'next', 'order', 'sushi', 'pizza', 'which', 'never', 'good', 'their', 'waiter', 'ask', 'them', 'they', 'ever', 'receive', 'they', 'that', 'they', 'that', 'they', 'figure', 'just', 'forget', 'they', 'long', 'want', 'cancel', 'they', 'can', 'their', 'really', 'part', 'they', 'can', 'just', 'improve', 'their', 'service', 'talk', 'major', 'improvement', 'give', 'numb', 'star', 'unfortunately', 'teach', 'them', 'lesson', 'go', 'back', 'again', 'despite', 'terrible', 'service', 'guess', 'what', 'difference', 'doe', 'make', 'them', 'they', 'money', 'clearly', 'other', 'people', 'money', 'they', 'happy', 'though', 'they', 'do', 'everything', 'right']\n",
      "['this', 'place', 'terrible', 'girlfriend', 'be', 'search', 'something', 'unique', 'stumble', 'upon', 'melt', 'last', 'night', 'have', 'never', 'fondue', 'hear', 'story', 'much', 'that', 'experience', 'that', 'everyone', 'should', 'sunday', 'night', 'expect', 'which', 'when', '\\ufeff1', 'walk', 'hostess', 'very', 'polite', 'understand', 'they', 'decide', 'take', 'down', 'phone', 'numb', 'just', 'them', 'there', 'be', 'maybe', 'numb', 'numb', 'other', 'table', 'people', 'they', 'seat', 'back', 'restaurant', 'which', 'pretty', 'disrespectful', 'opinion', 'hostess', 'explain', 'work', 'drink', 'order', 'after', 'about', 'numb', 'minute', 'sit', 'there', 'still', 'drink', 'finally', 'server', 'ask', 'what', 'want', 'drink', 'polite', 'good', 'much', 'depth', 'suggest', 'that', 'order', 'numb', 'course', 'meal', 'after', 'another', 'numb', 'numb', 'minute', 'finally', 'glass', 'water', 'drink', 'be', 'sit', 'there', 'about', 'numb', 'numb', 'minute', 'without', 'even', 'water', 'sit', 'there', 'sip', 'drink', 'have', 'already', 'decide', 'what', 'be', 'go', 'server', 'back', 'take', 'order', 'this', 'about', 'another', 'numb', 'minute', 'from', 'last', 'manager', 'drop', 'drink', 'sit', 'there', 'unroll', 'silverware', 'notice', 'large', 'amount', 'prong', 'server', 'about', 'politely', 'take', 'them', 'order', 'bring', 'numb', 'numb', 'minute', 'late', 'arrive', 'with', '\\ufeff1', 'cheese', 'choice', 'make', 'cheese', 'walk', 'without', 'give', 'utensil', 'across', 'empty', 'table', 'across', 'from', 'minute', 'late', 'come', 'back', 'finally', 'drop', 'same', 'thing', 'when', 'dirty', 'rust', 'numb', 'different', 'cheese', 'choice', 'disgust', 'bland', 'flavor', 'finish', 'with', '\\ufeff1', 'cheese', 'do', 'with', 'drink', 'server', 'come', 'over', 'grab', 'clean', 'salad', 'plate', 'never', 'want', 'much', 'drink', 'even', 'though', 'glass', 'be', 'since', 'only', 'once', 'every', 'numb', 'numb', 'minute', 'that', 'still', 'annoy', 'order', 'drink', 'luckily', 'manager', 'behind', 'ask', 'order', 'through', 'server', 'would', 'bring', 'drink', 'right', 'bring', 'them', 'that', 'they', 'be', 'go', 'house', 'awesome', 'onto', 'entree', 'order', 'cajun', 'spice', 'numb', 'different', 'type', 'steak', 'chicken', 'shrimp', 'waitress', 'cook', 'time', 'give', 'timer', 'cellphone', 'time', 'portion', 'be', 'literally', 'numb', 'bite', 'steak', 'numb', 'shrimp', 'numb', 'small', 'bite', 'numb', 'chicken', 'wrap', 'thing', 'honestly', 'each', 'about', 'average', 'that', 'use', 'make', 'taste', 'garbage', 'absolutely', 'terrible', 'would', 'have', 'be', 'well', 'would', 'have', 'cook', 'bland', 'cheese', 'they', 'really', 'figure', 'different', 'spice', 'that', 'have', 'some', 'cajun', 'flavor', 'only', 'somewhat', 'save', 'grace', 'be', 'side', 'sauce', 'they', 'give', 'some', 'decent', 'flavor', 'steak', 'should', 'never', 'sauce', 'this', 'stuff', 'mandatory', 'only', 'save', 'portion', 'dessert', 'amaze', 'dessert', 'here', 'that', 'only', 'reason', 'give', 'numb', 'star', 'white', 'chocolate', 'chocolate', 'same', 'fruit', 'treat', 'amaze', 'chocolate', 'honestly', 'there', 'drink', 'anything', 'else', 'after', 'somewhere', 'else', 'will', 'finally', 'check', 'this', 'place', 'outrageous', '\\ufeff1', 'try', 'charge', 'beer', 'that', 'manager', 'be', 'go', 'after', 'tell', 'charge', 'still', 'annoy', 'total', 'price', 'numb', 'dollar', 'this', 'numb', 'meal', 'numb', 'beer', 'total', 'have', 'problem', 'spend', 'numb', 'numb', 'plate', 'amaze', 'this', 'worth', 'anywhere', 'close', 'that', 'price', 'around', 'numb', 'numb', 'person', 'would', 'have', 'be', 'much', 'acceptable', 'literally', 'numb', 'numb', 'piece', 'each', 'they', 'must', 'average', 'size', 'steak', 'give', 'little', 'numb', 'numb', 'people', 'final', 'thought', 'anyone', 'talk', 'highly', 'this', 'place', 'because', 'they', 'pretend', 'classy', 'uppity', 'restaurant', 'cater', 'high', 'clientele', 'that', 'they', 'think', 'they', 'well', 'then', 'everyone', 'else', 'only', 'reason', 'this', 'place', 'still', 'desert', 'they', 'finish', 'dessert', 'they', 'have', 'forget', 'terribly', 'bland', 'overpriced', 'that']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "['great', 'coffeeeeeeeee', 'great', 'service', 'very', 'place']\n",
      "['this', 'place', 'great', 'great', 'service']\n"
     ]
    }
   ],
   "source": [
    "model = textacy.TopicModel(model_name, n_topics=n_topics)\n",
    "model.fit(input_matrix)\n",
    "doc_topic_matrix = model.transform(input_matrix)\n",
    "\n",
    "for topic_idx, top_terms in model.top_topic_terms(vectorizer.get_feature_names()):\n",
    "    print('topic', topic_idx, ':', '   '.join(top_terms))\n",
    "\n",
    "for topic_idx, top_docs in model.top_topic_docs(doc_topic_matrix, topics=[0,1], top_n=2):\n",
    "    print(topic_idx)\n",
    "    for j in top_docs:\n",
    "        print(rests[j])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic 0 : that   much   there   just   really   than   what   think   little   well\n",
      "topic 1 : great   service   atmosphere   price   awesome   excellent   drink   selection   happy   fantastic\n",
      "topic 2 : pizza   crust   slice   cheese   wing   topping   pepperoni   delivery   sauce   salad\n",
      "topic 3 : numb   star   minute   only   price   about   give   people   around   hour\n",
      "topic 4 : with   sauce   salad   which   cheese   side   delicious   also   steak   flavor\n",
      "topic 5 : place   this   recommend   favorite   vega   have   look   your   from   awesome\n",
      "topic 6 : they   have   them   also   make   your   when   close   because   offer\n",
      "topic 7 : very   price   restaurant   service   tasty   excellent   reasonable   portion   clean   good\n",
      "topic 8 : sushi   roll   fresh   sashimi   quality   price   salmon   japanese   tempura   buffet\n",
      "topic 9 : order   minute   service   when   wait   ask   after   table   take   never\n",
      "topic 10 : burger   fry   burgers   cheese   onion   shake   bacon   patty   ring   joint\n",
      "topic 11 : chicken   fry   sauce   spicy   order   curry   waffle   wing   noodle   taste\n",
      "topic 12 : breakfast   coffee   pancake   toast   brunch   bacon   morning   burrito   french   waffle\n",
      "topic 13 : back   will   definitely   again   here   come   ﻿1   delicious   go   next\n",
      "topic 14 : always   here   time   favorite   have   never   every   come   service   fresh\n",
      "topic 15 : be   there   time   both   table   drink   here   night   have   seat\n",
      "topic 16 : friendly   staff   super   clean   delicious   helpful   attentive   quick   atmosphere   fresh\n",
      "topic 17 : sandwich   lunch   bread   salad   cheese   turkey   fresh   grill   pull   pastrami\n",
      "topic 18 : amaze   recommend   highly   service   delicious   everything   absolutely   restaurant   ever   vega\n",
      "topic 19 : their   try   also   really   special   dish   customer   other   favorite   location\n",
      "0\n",
      "['that']\n",
      "['that']\n",
      "1\n",
      "['great', 'service', 'great']\n",
      "['great', 'great', 'service']\n",
      "2\n",
      "['pizza']\n",
      "['強烈推薦白pizza', '來vegas超過10次', '第一次來試secret', 'pizza', '薄片pizza', '朋友們也說很讚', '是個不錯簡單的好選擇']\n",
      "3\n",
      "['ステーキ店を探して行き着いたのがこの店', '有名なお店とはつゆ知らず', '入ってみて値段にビックリ', 'yelpの$を全くチェックしていませんでした', 'まあ入ってしまったからにはステーキを注文', '骨付ステーキを注文したは良いが', 'なんとソースが7$ってどういうこと', 'これはやられたと思いながらも待って出てきたのは14ozステーキ', '微かに焦げがあるのが香ばしくそのままでも美味しいです', 'numb', 'のソースやらを付けてみました', 'なんとものすごく美味しい', 'フルーツを煮込んだような甘酸っぱいソースはお店の拘りのよう', 'numb', 'の訳はここにあったかなと', 'お店の雰囲気はちょっと大人むけ', '店員の女性はみなボディコンミニ', '子供を連れて行くには問題ありな気がします']\n",
      "['ミラージュホテルの中にあるデリ', '他の方の写真にもあるとおり本当はもの凄く背の高いパストラミサンドイッチが名物なのですが', '見た目からしてあまりに大きくて食べたことがありません', '大抵はチーズケーキとコーヒーをオーダーします', 'カウンターでオーダーして支払いを済ませてから', 'テイクアウトも可', 'ドリンクやフードを持ってきてくれます', 'チーズケーキに関して言えば可もなく不可もなくいわゆるアメリカンな味です', 'かなりしっかりしているので食事の前にうっかり食べてしまうとこれだけでお腹いっぱいになってしまうかもしれません', '24時間営業なので深夜にお腹が空いたときに重宝します', 'numb', 'numb', 'パストラミサンドイッチを食べました', '写真もアップしましたがこれだけで17ドル台です', '特別高いかというとラスベガスの今の標準的価格帯でしょう', 'かなりしっかりとパストラミが入っています', '他には何も入っていなくてパストラミだけ', '名前に偽りなしです', 'これだけでかなりお腹いっぱいになります', '最初から半分に切って出てくるので半分は持ち帰ったり', '人とわけるのもありだと思います']\n",
      "4\n",
      "['with']\n",
      "['with']\n"
     ]
    }
   ],
   "source": [
    "model = textacy.TopicModel('nmf', n_topics=20)\n",
    "model.fit(doc_term_matrix)\n",
    "doc_topic_matrix = model.transform(doc_term_matrix)\n",
    "\n",
    "for topic_idx, top_terms in model.top_topic_terms(vectorizer.get_feature_names()):\n",
    "    print('topic', topic_idx, ':', '   '.join(top_terms))\n",
    "\n",
    "for topic_idx, top_docs in model.top_topic_docs(doc_topic_matrix, topics=[0, 1, 2, 3, 4], top_n=2):\n",
    "    print(topic_idx)\n",
    "    for i in top_docs:\n",
    "        print(rests[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('../models/nmf.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
